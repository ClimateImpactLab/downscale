{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import collections\n",
    "import os \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import xesmf as xe\n",
    "\n",
    "from utils import _convert_lons, _remove_leap_days, compute_daily_climo\n",
    "from regridding import apply_weights\n",
    "\n",
    "import dask.distributed as dd\n",
    "import dask_kubernetes as dk\n",
    "import dask\n",
    "import rhg_compute_tools.kubernetes as rhgk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is a test of all the steps for Spatial Disaggregation to get a handle on the total CPU time it will take for this part of BCSD. \n",
    "\n",
    "Once-off steps: \n",
    "\n",
    "1. compute multi-decade daily climatologies of ERA-5 at obs-res and coarsen it to model-res (they, e.g. NASA-NEX, do not say how, we will do bilinear for consistency with later step)\n",
    "\n",
    "Per model/scenario/experiment steps:\n",
    "\n",
    "1. subtract (or divide for precip) BC’ed model data at model-res from obs climo at model resolution to calculate a “scaling factor” \n",
    "2. bilinearly interpolate “scaling factor” (using xESMF) from the model grid to the obs grid \n",
    "3. Apply scaling factor by adding (for temp) and multiplying (for precip) the “scaling factor” to the obs-res daily climatology \n",
    "\n",
    "NOTE: For the purpose of being conservative with timing, the \"coarsen obs climatology step to model-res\" is in the per model/scenario/experiment step, since we don't know for sure how/if CMIP6 models will be at exactly the same resolution. \n",
    "\n",
    "Currently this workflow is only built out for temperature, not precipitation. All steps are included, the last step (applying the interpolated scale factor to the obs-res daily climatology) has not yet been tested. All other parts of the workflow have been tested. The second to last step, the interpolation of the scaling factor from coarse to fine, is the most memory intensive, thus I have only tested for a subset of timesteps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0f4f5583ee4e0bba03bdeeff41ba41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>KubeCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    .…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client, cluster = rhgk.get_standard_cluster()\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load test bias corrected output from global bias correction prototype notebook (BC'ed NASA GISS CMIP6 data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_model = xr.open_dataset('/home/jovyan/global_bias_correction_scaling_test.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax_model = var_model.rename({'lat': 'latitude', 'lon': 'longitude'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax_obs = xr.open_mfdataset(os.path.join('/gcs/rhg-data/climate/source_data/GMFD/tmax', \n",
    "                                         'tmax_0p25_daily_199*'), concat_dim='time',\n",
    "                              parallel=True).squeeze(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize longitudes \n",
    "tmax_obs = _convert_lons(tmax_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove leap days from obs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove leap days \n",
    "# tmax_obs = tmax_obs.sel(time=~((tmax_obs.time.dt.month == 2) & (tmax_obs.time.dt.day == 29)))\n",
    "tmax_obs = _remove_leap_days(tmax_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_chunks = {'time': -1, 'latitude': 75, 'longitude': 75}\n",
    "day_chunks = {'dayofyear': 1, 'latitude': -1, 'longitude': -1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load daily obs climatology "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "climo_obs_fine = xr.open_dataset(\"/home/jovyan/gmfd_test_climo.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate obs climo: fine -> coarse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuse existing file: /home/jovyan/obs_to_mod_bilinear_spatial_disagg.nc\n",
      "CPU times: user 224 ms, sys: 23.3 ms, total: 247 ms\n",
      "Wall time: 365 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "obs_to_mod_weights = '/home/jovyan/obs_to_mod_bilinear_spatial_disagg.nc'\n",
    "regridder_obs_to_mod = xe.Regridder(tmax_obs.isel(time=0).rename({'latitude': 'lat', 'longitude': 'lon'}), \n",
    "                                    tmax_model.isel(time=0).rename({'latitude': 'lat', 'longitude': 'lon'}), \n",
    "                         'bilinear', filename=obs_to_mod_weights, reuse_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.32 s, sys: 1.83 s, total: 3.14 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "climo_obs_coarse_lazy = xr.map_blocks(apply_weights, regridder_obs_to_mod, \n",
    "                                args=[climo_obs_fine['tmax'].rename({'latitude': 'lat', 'longitude': 'lon'})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 709 µs, sys: 0 ns, total: 709 µs\n",
      "Wall time: 716 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "climo_obs_coarse = climo_obs_coarse_lazy.rename({'lat': 'latitude', 'lon': 'longitude'}).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute scaling factor by subtracting for temperature, dividing for precip, the BC'ed model data at model-res from obs climo at model-res. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_anomaly(ds, climo, var_name):\n",
    "    # Necessary workaround to xarray's check with zero dimensions\n",
    "    # https://github.com/pydata/xarray/issues/3575\n",
    "    da = ds[var_name]\n",
    "    if sum(da.shape) == 0:\n",
    "        return da\n",
    "    groupby_type = ds.time.dt.dayofyear\n",
    "    gb = da.groupby(groupby_type)\n",
    "    \n",
    "    return gb - climo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = {'latitude': 75, 'longitude': 75}\n",
    "\n",
    "climo_obs_coarse = climo_obs_coarse.chunk(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.04 s, sys: 411 ms, total: 3.45 s\n",
      "Wall time: 4.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "scale_factor_coarse = xr.map_blocks(_calculate_anomaly, \n",
    "                                    tmax_model, args=[climo_obs_coarse, 'tasmax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.9 s, sys: 2.53 s, total: 28.4 s\n",
      "Wall time: 28 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "sfc = scale_factor_coarse.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate scaling factor: coarse (model grid) -> fine (obs grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuse existing file: /home/jovyan/mod_to_obs_bilinear_spatial_disagg.nc\n",
      "CPU times: user 132 ms, sys: 82.6 ms, total: 214 ms\n",
      "Wall time: 901 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mod_to_obs_weights = '/home/jovyan/mod_to_obs_bilinear_spatial_disagg.nc'\n",
    "regridder_mod_to_obs = xe.Regridder(tmax_model.isel(time=0).rename({'latitude': 'lat', 'longitude': 'lon'}), \n",
    "                                    tmax_obs.isel(time=0).rename({'latitude': 'lat', 'longitude': 'lon'}), \n",
    "                         'bilinear', filename=mod_to_obs_weights, reuse_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfc = sfc.drop('dayofyear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.8 s, sys: 39.1 s, total: 1min 23s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sff_lazy = xr.map_blocks(apply_weights, regridder_mod_to_obs, \n",
    "                                args=[sfc.rename({'latitude': 'lat', 'longitude': 'lon'})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 456 µs, sys: 0 ns, total: 456 µs\n",
      "Wall time: 463 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sff_lazy_compute = sff_lazy.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add (or multiply for precip) the scaling factor to the obs-res daily climatology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sff_ds = sff_lazy_compute.to_dataset(name='scale_factor_fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.7 s, sys: 361 ms, total: 49.1 s\n",
      "Wall time: 46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sff_chunks = {'time': -1, 'lat': 55, 'lon': 55}\n",
    "sff_ds = sff_ds.chunk(sff_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.54 ms, sys: 1.17 ms, total: 7.71 ms\n",
      "Wall time: 6.88 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cof_chunks = {'latitude': 55, 'longitude': 55}\n",
    "climo_obs_fine = climo_obs_fine.chunk(cof_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_scale_factor(ds_sff, obs_climo):\n",
    "    da = ds_sff['scale_factor_fine'].transpose(\"latitude\", \"longitude\", \"time\")\n",
    "    \n",
    "    if sum(ds.shape) == 0:\n",
    "        return ds\n",
    "    \n",
    "    groupby_type = ds_sff.time.dt.dayofyear\n",
    "    \n",
    "    sff_daily = da.groupby(groupby_type)\n",
    "    return sff_daily + obs_climo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 507 ms, sys: 13.6 ms, total: 520 ms\n",
      "Wall time: 501 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "model_ds = xr.map_blocks(apply_scale_factor, sff_ds.rename({'lat': 'latitude', 'lon': 'longitude'}), \n",
    "                         args=[climo_obs_fine['tmax']], template=sff_ds.rename({'lat': 'latitude', 'lon': 'longitude'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4367e44b1e3743bca4fbe7263be537c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_downscaled = model_ds.persist()\n",
    "dd.progress(model_downscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_downscaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply standardizing functions for final output and save (probably as zarr array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
