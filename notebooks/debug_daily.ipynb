{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import collections\n",
    "# import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# sns.set(style='darkgrid')\n",
    "\n",
    "from skdownscale.pointwise_models import BcsdTemperature, BcsdPrecipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skdownscale.pointwise_models import PaddedDOYGrouper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install probscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = get_sample_data('training')\n",
    "targets = get_sample_data('targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.23.2.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_slice = slice('1980-01-01', '1989-12-31')\n",
    "predict_slice = slice('1990-01-01', '1999-12-31')\n",
    "\n",
    "# extract training / prediction data\n",
    "X_train = training[['tmax']][train_slice]\n",
    "y_train = targets[['tmax']][train_slice]\n",
    "X_predict = training[['tmax']][predict_slice]\n",
    "    \n",
    "model = BcsdTemperature(return_anoms=False).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_noleap = X_train[~((X_train.index.month == 2) & (X_train.index.day == 29))]\n",
    "ts_daysofyear = X_train.index.dayofyear\n",
    "padded_doy = np.pad(ts_daysofyear, 15, mode=\"wrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_noleap[((X_train_noleap.index.month == 2) & (X_train_noleap.index.day == 29))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tests to add to scikit-downscale "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for testing PaddedDOYGrouper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.date_range(start='1980-01-01', end='1982-12-31')\n",
    "X = pd.DataFrame({'foo': np.random.random(len(index))}, index=index)\n",
    "day_groups = PaddedDOYGrouper(X)\n",
    "u = PaddedDOYGrouper(X_train_noleap[slice('1981-01-01', '1982-12-31')])\n",
    "doy_group_list = dict(list(u))\n",
    "\n",
    "day_of_year = 123\n",
    "days_included = np.arange(day_of_year - 15, day_of_year + 16)\n",
    "days_included_to_fail = np.arange(day_of_year - 15, day_of_year + 18)\n",
    "np.testing.assert_array_equal(np.unique(doy_group_list[day_of_year].index.dayofyear), days_included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(doy_group_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u = X_train.groupby(PaddedDOYGrouper)\n",
    "u = PaddedDOYGrouper(X_train_noleap[slice('1980-01-01', '1982-12-31')])\n",
    "# u = PaddedDOYGrouper(X_train[slice('1980-01-01', '1982-12-31')])\n",
    "doy_group_list = dict(list(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.pad(np.arange(1, 366), 15, mode=\"wrap\")\n",
    "i = 0\n",
    "offset = 15\n",
    "n = 1\n",
    "total_days = (2 * offset) + 1\n",
    "first_half = v[i : i + offset]\n",
    "sec_half = v[n + offset : i + total_days]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "       364, 365])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980-03-22 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1980-03-07', '1980-03-08', '1980-03-09', '1980-03-10',\n",
       "               '1980-03-11', '1980-03-12', '1980-03-13', '1980-03-14',\n",
       "               '1980-03-15', '1980-03-16', '1980-03-17', '1980-03-18',\n",
       "               '1980-03-19', '1980-03-20', '1980-03-21', '1980-03-22',\n",
       "               '1980-03-23', '1980-03-24', '1980-03-25', '1980-03-26',\n",
       "               '1980-03-27', '1980-03-28', '1980-03-29', '1980-03-30',\n",
       "               '1980-03-31', '1980-04-01', '1980-04-02', '1980-04-03',\n",
       "               '1980-04-04', '1980-04-05', '1980-04-06', '1981-03-08',\n",
       "               '1981-03-09', '1981-03-10', '1981-03-11', '1981-03-12',\n",
       "               '1981-03-13', '1981-03-14', '1981-03-15', '1981-03-16',\n",
       "               '1981-03-17', '1981-03-18', '1981-03-19', '1981-03-20',\n",
       "               '1981-03-21', '1981-03-22', '1981-03-23', '1981-03-24',\n",
       "               '1981-03-25', '1981-03-26', '1981-03-27', '1981-03-28',\n",
       "               '1981-03-29', '1981-03-30', '1981-03-31', '1981-04-01',\n",
       "               '1981-04-02', '1981-04-03', '1981-04-04', '1981-04-05',\n",
       "               '1981-04-06', '1981-04-07', '1982-03-08', '1982-03-09',\n",
       "               '1982-03-10', '1982-03-11', '1982-03-12', '1982-03-13',\n",
       "               '1982-03-14', '1982-03-15', '1982-03-16', '1982-03-17',\n",
       "               '1982-03-18', '1982-03-19', '1982-03-20', '1982-03-21',\n",
       "               '1982-03-22', '1982-03-23', '1982-03-24', '1982-03-25',\n",
       "               '1982-03-26', '1982-03-27', '1982-03-28', '1982-03-29',\n",
       "               '1982-03-30', '1982-03-31', '1982-04-01', '1982-04-02',\n",
       "               '1982-04-03', '1982-04-04', '1982-04-05', '1982-04-06',\n",
       "               '1982-04-07'],\n",
       "              dtype='datetime64[ns]', name='time', freq=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_days = pd.date_range(start='1980-01-01', end='1982-12-31')\n",
    "print(year_days[81])\n",
    "doy_group_list[82].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leap day check to add into PaddedDOYGrouper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_noleap[((X_train_noleap.index.month == 2) & (X_train_noleap.index.day == 29))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pd.DataFrame(index = X_predict.index)\n",
    "\n",
    "# X_rolling_mean, x_climo, y_climo, Xqm, X_no_shift, X, X_shift, df_bc = model.predict(X_predict)\n",
    "df_bc = model.predict(X_predict)\n",
    "predict_df['BCSD'] = df_bc.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-01</th>\n",
       "      <td>4.528703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-02</th>\n",
       "      <td>-1.584749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-03</th>\n",
       "      <td>2.848937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-04</th>\n",
       "      <td>6.687826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-05</th>\n",
       "      <td>8.296425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-27</th>\n",
       "      <td>19.128365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-28</th>\n",
       "      <td>16.533390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-29</th>\n",
       "      <td>8.740290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-30</th>\n",
       "      <td>3.565762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-31</th>\n",
       "      <td>4.326358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3652 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tmax\n",
       "time                 \n",
       "1990-01-01   4.528703\n",
       "1990-01-02  -1.584749\n",
       "1990-01-03   2.848937\n",
       "1990-01-04   6.687826\n",
       "1990-01-05   8.296425\n",
       "...               ...\n",
       "1999-12-27  19.128365\n",
       "1999-12-28  16.533390\n",
       "1999-12-29   8.740290\n",
       "1999-12-30   3.565762\n",
       "1999-12-31   4.326358\n",
       "\n",
       "[3652 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_df['BCSD'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fig, ax = plt.subplots(figsize=(8, 3.5))\\n\\ntime_slice = slice(\\'1990-01-01\\', \\'1990-12-31\\')\\n\\ntargets[\\'tmax\\'][time_slice].plot(ax=ax, label=\\'target\\', linestyle=\"--\", c=\\'red\\', lw=1, alpha=0.75, legend=True, zorder=10)\\n\\ntraining[\\'tmax\\'][time_slice].plot(label=\\'original\\', linestyle=\"--\", c=\\'k\\', ax=ax, alpha=0.75, legend=True)\\n\\npredict_df[time_slice].plot(ax=ax, linestyle=\"-\", c=\\'blue\\', alpha=0.75, legend=True)\\n\\nax.legend(loc=\\'center left\\', bbox_to_anchor=(1, 0.5))\\n_ = ax.set_ylabel(\\'Temperature [C]\\')'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''fig, ax = plt.subplots(figsize=(8, 3.5))\n",
    "\n",
    "time_slice = slice('1990-01-01', '1990-12-31')\n",
    "\n",
    "targets['tmax'][time_slice].plot(ax=ax, label='target', linestyle=\"--\", c='red', lw=1, alpha=0.75, legend=True, zorder=10)\n",
    "\n",
    "training['tmax'][time_slice].plot(label='original', linestyle=\"--\", c='k', ax=ax, alpha=0.75, legend=True)\n",
    "\n",
    "predict_df[time_slice].plot(ax=ax, linestyle=\"-\", c='blue', alpha=0.75, legend=True)\n",
    "\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "_ = ax.set_ylabel('Temperature [C]')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### switch to our NASA-NEX daily implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove leap days \n",
    "training_noleap = training[~((training.index.month == 2) & (training.index.day == 29))]\n",
    "targets_noleap = targets[~((targets.index.month == 2) & (targets.index.day == 29))]\n",
    "\n",
    "# extract training / prediction data\n",
    "X_train_noleap = training_noleap[['tmax']][train_slice]\n",
    "y_train_noleap = targets_noleap[['tmax']][train_slice]\n",
    "X_predict_noleap = training_noleap[['tmax']][predict_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nasanex = BcsdTemperature(time_grouper='daily_nasa-nex', return_anoms=False).fit(X_train_noleap, \n",
    "                                                                                       y_train_noleap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_nasanex = BcsdTemperature(time_grouper='daily_nasa-nex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert issubclass(model_nasanex.time_grouper, PaddedDOYGrouper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.full((365, 1), np.inf)\n",
    "u[100] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df_nasanex = pd.DataFrame(index = X_predict_noleap.index)\n",
    "\n",
    "df_bc_nasanex = model_nasanex.predict(X_predict_noleap)\n",
    "\n",
    "predict_df_nasanex['BCSD'] = df_bc_nasanex.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 3.5))\n",
    "\n",
    "time_slice_compare = slice('1990-01-01', '1991-01-01')\n",
    "\n",
    "# X_predict_noleap['tmax'][time_slice_compare].plot(ax=ax, color='red', label='GCM')\n",
    "\n",
    "targets['tmax'][time_slice_compare].plot(ax=ax, color='black', linestyle=':', label='targets/obs')\n",
    "\n",
    "predict_df['BCSD'][time_slice_compare].plot(ax=ax, color='black', linestyle='-', alpha=.75, label='monthly')\n",
    "predict_df_nasanex['BCSD'][time_slice_compare].plot(ax=ax, color='blue', linestyle='-', alpha=.75, label='nasa-nex')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.ylabel('Temperature ($^\\circ$C)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 3.5))\n",
    "\n",
    "'''predict_df['BCSD'].plot(color='black', linestyle=':', alpha=.75, label='Joe')\n",
    "predict_df_nasanex['BCSD'].plot(color='blue', linestyle=':', alpha=.75, label='me')'''\n",
    "\n",
    "diff = predict_df_nasanex['BCSD'] - predict_df['BCSD']\n",
    "\n",
    "'''predict_df['BCSD'][time_slice_compare].plot(color='black', linestyle='-', alpha=.75, label='monthly')\n",
    "predict_df_nasanex['BCSD'][time_slice_compare].plot(color='blue', linestyle='-', alpha=.75, label='nasa-nex')'''\n",
    "\n",
    "diff.plot()\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now test precipitation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract training / prediction data\n",
    "X_train = training[['pcp']][train_slice]\n",
    "y_train = targets[['pcp']][train_slice]\n",
    "X_predict = training[['pcp']][predict_slice]\n",
    "    \n",
    "model = BcsdPrecipitation(return_anoms=False).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pd.DataFrame(index = X_predict.index)\n",
    "\n",
    "df_bc = model.predict(X_predict)\n",
    "predict_df['BCSD'] = df_bc.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove leap days \n",
    "training_noleap = training[~((training.index.month == 2) & (training.index.day == 29))]\n",
    "targets_noleap = targets[~((targets.index.month == 2) & (targets.index.day == 29))]\n",
    "\n",
    "# extract training / prediction data\n",
    "X_train_noleap = training_noleap[['pcp']][train_slice]\n",
    "y_train_noleap = targets_noleap[['pcp']][train_slice]\n",
    "X_predict_noleap = training_noleap[['pcp']][predict_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nasanex = BcsdPrecipitation(time_grouper='daily_nasa-nex', return_anoms=False).fit(X_train_noleap, \n",
    "                                                                                       y_train_noleap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df_nasanex = pd.DataFrame(index = X_predict_noleap.index)\n",
    "\n",
    "df_bc_nasanex = model_nasanex.predict(X_predict_noleap)\n",
    "\n",
    "predict_df_nasanex['BCSD'] = df_bc_nasanex.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 3.5))\n",
    "\n",
    "time_slice_compare = slice('1990-01-01', '1991-01-01')\n",
    "\n",
    "X_predict_noleap['pcp'][time_slice_compare].plot(ax=ax, color='brown', linestyle=':', label='GCM')\n",
    "\n",
    "targets['pcp'][time_slice_compare].plot(ax=ax, color='black', linestyle=':', label='targets/obs')\n",
    "\n",
    "predict_df['BCSD'][time_slice_compare].plot(ax=ax, color='red', linestyle='-', alpha=.75, label='monthly')\n",
    "\n",
    "predict_df_nasanex['BCSD'][time_slice_compare].plot(ax=ax, color='blue', linestyle='-', alpha=.75, label='nasa-nex')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.time_grouper(df)\n",
    "doy_groups = PaddedDOYGrouper(x_rolling_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DAY_GROUPER(x):\n",
    "    return x.day\n",
    "doy_groups_day = X_train_noleap.groupby(DAY_GROUPER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doy_groups.get_group(10).head()\n",
    "doy_group_list = dict(list(doy_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group - climatology.loc[key]\n",
    "# doy_group_list[100] - x_climo[100]\n",
    "# doy_group_list[100] - x_climo.loc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for key, group in doy_groups_day:\n",
    "    dfs.append(group - x_climo.loc[key])\n",
    "\n",
    "out = pd.concat(dfs).sort_index()\n",
    "assert x_rolling_mean.shape == out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_rolling_mean.shape)\n",
    "print(len(dfs))\n",
    "print(out.shape)\n",
    "dfs[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# def MONTH_GROUPER(x):\n",
    "    return x.month\n",
    "def _create_groups(self, df):\n",
    "        \"\"\" helper function to create groups by either daily or month,\n",
    "        depending on whether we are bias correcting daily or monthly data\n",
    "        \"\"\"\n",
    "        if self.timestep == 'monthly':\n",
    "            return df.groupby(self.time_grouper)\n",
    "        elif self.timestep== 'daily':\n",
    "            return self.time_grouper(df)\n",
    "        else:\n",
    "            raise TypeError('unexpected time grouper type %s' % self.time_grouper)\n",
    "# self._x_climo = self._create_groups(X).mean()\n",
    "month_groups = X_train_noleap.groupby(MONTH_GROUPER)\n",
    "\n",
    "# self.time_grouper(df)\n",
    "doy_groups = PaddedDOYGrouper(x_rolling_mean)\n",
    "\n",
    "doy_training = PaddedDOYGrouper(X_train_noleap)\n",
    "\n",
    "month_groups.get_group(6).head()\n",
    "\n",
    "# doy_groups.get_group(10).head()\n",
    "doy_group_list = dict(list(doy_groups))\n",
    "\n",
    "doy_group_list_training = dict(list(doy_training))\n",
    "\n",
    "days_of_year = np.arange(1, 366)\n",
    "days_of_year_wrapped = np.pad(days_of_year, 15, mode='wrap')\n",
    "n = 5\n",
    "offset = 15\n",
    "i = n - 1\n",
    "total_days = (2 * offset) + 1\n",
    "\n",
    "first_half = days_of_year_wrapped[i:i+offset]\n",
    "# sec_half = days_of_year_wrapped[i+offset:i+total_days]\n",
    "sec_half = days_of_year_wrapped[n+offset:i+total_days]\n",
    "all_days = np.concatenate((first_half, np.array([n]), sec_half), axis=0)\n",
    "'''print(first_half)\n",
    "print(sec_half)\n",
    "print(all_days)\n",
    "print(len(first_half))\n",
    "print(len(sec_half))\n",
    "print(len(all_days))'''\n",
    "\n",
    "assert len(set(all_days)) == total_days, all_days\n",
    "\n",
    "result = X_train_noleap[X_train_noleap.index.dayofyear.isin(all_days)]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "downscale_latest_latest",
   "language": "python",
   "name": "downscale_latest_latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
