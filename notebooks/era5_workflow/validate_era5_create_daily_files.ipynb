{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Perform validation on newly downoaded data. Then, calculate the daily tmin, tmax and tas (2-m average) to save yearly files. Update to Diana's 'era5_download_and_aggregate_to_daily.ipynb' notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import xarray as xr\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "import dask\n",
    "import dask.array as dda\n",
    "import dask.distributed as dd\n",
    "\n",
    "# rhodium-specific kubernetes cluster configuration\n",
    "import rhg_compute_tools.kubernetes as rhgk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client, cluster = rhgk.get_standard_cluster()\n",
    "cluster.scale(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>gateway://traefik-impactlab-hub-dask-gateway.impactlab-hub:80/impactlab-hub.3a13a5f1a3b54706a7222adec9224b8f</li>\n",
       "  <li><b>Dashboard: </b><a href='/services/dask-gateway/clusters/impactlab-hub.3a13a5f1a3b54706a7222adec9224b8f/status' target='_blank'>/services/dask-gateway/clusters/impactlab-hub.3a13a5f1a3b54706a7222adec9224b8f/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>30</li>\n",
       "  <li><b>Cores: </b>30</li>\n",
       "  <li><b>Memory: </b>362.39 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tls://10.20.87.2:8786' processes=30 threads=30, memory=362.39 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "era_start = '01-01-1979' # 1979 \n",
    "era_end = '12-31-2020'   # 2020\n",
    "\n",
    "# make list of daily datetime indices, this includes leap years \n",
    "dt_index_full = pd.date_range(start=era_start, end=era_end, freq='D')\n",
    "\n",
    "# reformat month/day for the retrieval function \n",
    "dt_index_years = dt_index_full.year.astype(str)\n",
    "dt_index_months = dt_index_full.month.map(\"{:02}\".format)\n",
    "dt_index_days = dt_index_full.day.map(\"{:02}\".format)\n",
    "daynum = dt_index_full.dayofyear\n",
    "\n",
    "# make list of hours for retrieval function \n",
    "hours = [hr.strftime(\"%H:%M\") for hr in pd.date_range(start='10-09-2019', end='10-10-2019', freq='H')[:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation of ERA-5 daily files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_nans(ds):\n",
    "    # no nans\n",
    "    assert ds['t2m'].isnull().sum() == 0, \"there are nans!\"\n",
    "\n",
    "def test_temp_range(ds, var):\n",
    "    # make sure temp values are in a valid range\n",
    "    assert (ds[var].min() < 150.15) or (ds[var].max() > 350.15), \"temperature values are invalid\" # 0 to 50 C\n",
    "\n",
    "def test_low_temp_range(ds, var):\n",
    "    threshold = 180\n",
    "    location = ds[var].where(ds[var] < threshold)\n",
    "    num = np.count_nonzero(~np.isnan(location))\n",
    "    return num\n",
    "\n",
    "def test_high_temp_range(ds, var):\n",
    "    threshold = 330\n",
    "    location = ds[var].where(ds[var] > threshold)\n",
    "    num = np.count_nonzero(~np.isnan(location))\n",
    "    return num\n",
    "\n",
    "def test_polar_high_temp(ds, var):\n",
    "    threshold = 317 #315.5\n",
    "    loc_NH = ds[var].sel(latitude=slice(90,50)).where(ds[var].sel(latitude=slice(90,50)) > threshold)\n",
    "    num_NH = np.count_nonzero(~np.isnan(loc_NH))\n",
    "    \n",
    "    loc_SH = ds[var].sel(latitude=slice(-50,-90)).where(ds[var].sel(latitude=slice(-50,-90)) > threshold)\n",
    "    num_SH = np.count_nonzero(~np.isnan(loc_SH))\n",
    "    return num_NH, num_SH\n",
    "\n",
    "def validate_era5_temp(spec):\n",
    "    '''\n",
    "    validate ERA-5 hourly or daily temperature files. \n",
    "    works for hourly `t2m` or saved daily tas, tmin, tmax\n",
    "    '''\n",
    "    filepath, timestep, var = spec\n",
    "    \n",
    "    # first check to be sure file exists\n",
    "    if os.path.isfile(filepath):\n",
    "        pass\n",
    "    else:\n",
    "        raise FileNotFoundError(\"%s was not created\" %filepath)\n",
    "    # now validate: test for nans, correct num of timesteps, \n",
    "    # correct variable exists, and temperature range is not absurd \n",
    "    with xr.open_dataset(filepath) as ds:\n",
    "        test_for_nans(ds)\n",
    "        test_temp_range(ds, var)\n",
    "\n",
    "        occurrances_low = test_low_temp_range(ds, var)\n",
    "        if occurrances_low > 0:\n",
    "            return [occurrances_low, filepath]\n",
    "        \n",
    "        occurrances_high = test_high_temp_range(ds, var)\n",
    "        if occurrances_high > 0:\n",
    "            return [occurrances_high, filepath]\n",
    "        \n",
    "        [occur_NH, occur_SH] = test_polar_high_temp(ds, var)\n",
    "        if occur_NH or occur_SH > 0:\n",
    "            return [occur_NH, occur_SH, filepath]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_files = ['t2m_%s_%s_%s.nc' %(year, month, day) for year, month, \n",
    "               day in zip(dt_index_years, dt_index_months, dt_index_days)]\n",
    "hourly_dir = '/gcs/impactlab-data/climate/source_data/ERA-5/hourly'\n",
    "\n",
    "daily_filepaths = [os.path.join(hourly_dir, daily_file) for daily_file in daily_files]\n",
    "JOBS_validation = [(filepath, 'hourly', 't2m') for filepath in daily_filepaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "futures_validation = client.map(validate_era5_temp, JOBS_validation)\n",
    "dd.progress(futures_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gathers output from workers\n",
    "results = client.gather(futures_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test number of not None instances in results i.e. where a function 'failed'\n",
    "print(sum(x is not None for x in results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the output of above -- identifying where a value (and not None) is located -- only do if above is > 0\n",
    "list_results = [x is not None for x in results]\n",
    "\n",
    "# worker index for flagged output (if above = True)\n",
    "res = [i for i, val in enumerate(list_results) if val]\n",
    "\n",
    "for i in res:\n",
    "    print(results[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once validation is complete, create daily files of tmax, tmin and tas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_daily_era5_average(spec):\n",
    "    '''\n",
    "    calculate daily-averaged ERA-5 temperature data \n",
    "    '''\n",
    "    filepath, timestep = spec\n",
    "    var = 't2m'\n",
    "    with xr.open_dataset(filepath) as ds:\n",
    "        return(ds[var].mean('time'))\n",
    "\n",
    "def calc_daily_era5_tmax(spec):\n",
    "    '''\n",
    "    calculate daily-averaged ERA-5 temperature data \n",
    "    '''\n",
    "    filepath, timestep = spec\n",
    "    var = 't2m'\n",
    "    with xr.open_dataset(filepath) as ds:\n",
    "        return(ds[var].max('time'))\n",
    "\n",
    "def calc_daily_era5_tmin(spec):\n",
    "    '''\n",
    "    calculate daily-averaged ERA-5 temperature data \n",
    "    '''\n",
    "    filepath, timestep = spec\n",
    "    var = 't2m'\n",
    "    with xr.open_dataset(filepath) as ds:\n",
    "        return(ds[var].min('time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_files = ['t2m_%s_%s_%s.nc' %(year, month, day) for year, month, \n",
    "               day in zip(dt_index_years, dt_index_months, dt_index_days)]\n",
    "hourly_dir = '/gcs/impactlab-data/climate/source_data/ERA-5/hourly' # add /v5.1 for 2000-2006\n",
    "\n",
    "daily_filepaths = [os.path.join(hourly_dir, daily_file) for daily_file in daily_files]\n",
    "JOBS = [(filepath, 'hourly') for filepath in daily_filepaths] # , 't2m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.7 ms, sys: 6.15 ms, total: 43.8 ms\n",
      "Wall time: 42.2 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3fb504019648209979d3967180f34b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# tas\n",
    "futures_tas = client.map(calc_daily_era5_average, JOBS)\n",
    "dd.progress(futures_tas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_da_list = client.gather(futures_tas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate DataArrays in list \n",
    "tas_year = xr.concat(tas_da_list, dim='time')\n",
    "\n",
    "# add datetime index \n",
    "tas_year['time'] = dt_index_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split daily averages into yearly files and save**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_yearlong_dailydata_file(directory, year, ds, var):\n",
    "    '''\n",
    "    save file of daily data for one variable for one year\n",
    "    directory(str)\n",
    "    year(str)\n",
    "    ds(Dataset)\n",
    "    var(str)\n",
    "    '''\n",
    "    today = str(date.today())\n",
    "    daily_file = xr.Dataset( {var: ds},\n",
    "                           attrs={\n",
    "        'author': 'Meredith Fish',\n",
    "        'contact': 'meredith.fish@rutgers.edu',\n",
    "        'project': ('impactlab-rhg/climate/source-data/ERA-5'),\n",
    "        'source': ('impactlab-rhg/climate/downscaled/ERA-5/hourly'),\n",
    "        'created': today})\n",
    "    filename = '%s_daily_%s-%s.nc' %(var, year, year)\n",
    "    daily_file.to_netcdf(os.path.join(directory, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tas daily file \n",
    "directory = '/gcs/impactlab-data/climate/source_data/ERA-5/day/tas/v1.1'\n",
    "\n",
    "for i_yr in np.arange(1979,2021): # ALWAYS CHECK\n",
    "    tas_per_yr = tas_year.sel(time=slice('%s-01-01' %str(i_yr),'%s-12-31' %str(i_yr)))\n",
    "    save_yearlong_dailydata_file(directory, i_yr, tas_per_yr, 'tas') #year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeat for Tmax -- recreate JOBS file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41 ms, sys: 16.1 ms, total: 57.1 ms\n",
      "Wall time: 45.9 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8adf9b1ad3e54753af2dc5c7e8de9483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# tmax\n",
    "futures_tmax = client.map(calc_daily_era5_tmax, JOBS)\n",
    "dd.progress(futures_tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax_da_list = client.gather(futures_tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate DataArrays in list \n",
    "tmax_year = xr.concat(tmax_da_list, dim='time')\n",
    "\n",
    "# add datetime index \n",
    "tmax_year['time'] = dt_index_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tmax daily file \n",
    "directory = '/gcs/impactlab-data/climate/source_data/ERA-5/day/tmax/v1.1'\n",
    "\n",
    "for i_yr in np.arange(1979,2021):\n",
    "    tmax_per_yr = tmax_year.sel(time=slice('%s-01-01' %str(i_yr),'%s-12-31' %str(i_yr)))\n",
    "    save_yearlong_dailydata_file(directory, i_yr, tmax_per_yr, 'tmax') #year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeat for Tmin -- recreate JOBS file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.5 ms, sys: 1.37 ms, total: 33.8 ms\n",
      "Wall time: 32.2 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e360fe584306429bbb182cba230aa0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# tmin\n",
    "futures_tmin = client.map(calc_daily_era5_tmin, JOBS)\n",
    "dd.progress(futures_tmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin_da_list = client.gather(futures_tmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate DataArrays in list \n",
    "tmin_year = xr.concat(tmin_da_list, dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add datetime index \n",
    "tmin_year['time'] = dt_index_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tmin daily file \n",
    "directory = '/gcs/impactlab-data/climate/source_data/ERA-5/day/tmin/v1.1'\n",
    "\n",
    "for i_yr in np.arange(2019,2021):\n",
    "    tmin_per_yr = tmin_year.sel(time=slice('%s-01-01' %str(i_yr),'%s-12-31' %str(i_yr)))\n",
    "    save_yearlong_dailydata_file(directory, i_yr, tmin_per_yr, 'tmin') #year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- Check newly created files ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tas_daily_1979-1979.nc\ttas_daily_1993-1993.nc\ttas_daily_2007-2007.nc\n",
      "tas_daily_1980-1980.nc\ttas_daily_1994-1994.nc\ttas_daily_2008-2008.nc\n",
      "tas_daily_1981-1981.nc\ttas_daily_1995-1995.nc\ttas_daily_2009-2009.nc\n",
      "tas_daily_1982-1982.nc\ttas_daily_1996-1996.nc\ttas_daily_2010-2010.nc\n",
      "tas_daily_1983-1983.nc\ttas_daily_1997-1997.nc\ttas_daily_2011-2011.nc\n",
      "tas_daily_1984-1984.nc\ttas_daily_1998-1998.nc\ttas_daily_2012-2012.nc\n",
      "tas_daily_1985-1985.nc\ttas_daily_1999-1999.nc\ttas_daily_2013-2013.nc\n",
      "tas_daily_1986-1986.nc\ttas_daily_2000-2000.nc\ttas_daily_2014-2014.nc\n",
      "tas_daily_1987-1987.nc\ttas_daily_2001-2001.nc\ttas_daily_2015-2015.nc\n",
      "tas_daily_1988-1988.nc\ttas_daily_2002-2002.nc\ttas_daily_2016-2016.nc\n",
      "tas_daily_1989-1989.nc\ttas_daily_2003-2003.nc\ttas_daily_2017-2017.nc\n",
      "tas_daily_1990-1990.nc\ttas_daily_2004-2004.nc\ttas_daily_2018-2018.nc\n",
      "tas_daily_1991-1991.nc\ttas_daily_2005-2005.nc\ttas_daily_2019-2019.nc\n",
      "tas_daily_1992-1992.nc\ttas_daily_2006-2006.nc\ttas_daily_2020-2020.nc\n"
     ]
    }
   ],
   "source": [
    "! ls /gcs/impactlab-data/climate/source_data/ERA-5/day/tas/v1.1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
