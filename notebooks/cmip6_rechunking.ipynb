{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import xarray as xr\n",
    "import numpy as np \n",
    "import os \n",
    "\n",
    "import intake\n",
    "import zarr \n",
    "import gcsfs\n",
    "from rechunker import rechunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "import dask.distributed as dd\n",
    "import rhg_compute_tools.kubernetes as rhgk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client, cluster = rhgk.get_standard_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6347e6adf2a54bf4a6b35d1eb76bf651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>GatewayCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n<style scoped>\\n    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pull in some CMIP6 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search the catalog\n",
    "col = intake.open_esm_datastore(\"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\")\n",
    "cat = col.search(activity_id='ScenarioMIP', experiment_id='ssp370', table_id='day', variable_id='tasmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the data and do some cleanup\n",
    "ds_model = cat['ScenarioMIP.NOAA-GFDL.GFDL-ESM4.ssp370.day.gr1'].to_dask(\n",
    "    ).isel(member_id=0).squeeze(drop=True).drop(['height', 'member_id'])\n",
    "\n",
    "ds_model.lon.values[ds_model.lon.values > 180] -= 360\n",
    "ds_model = ds_model.roll(lon=72, roll_coords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = gcsfs.GCSFileSystem(token='/opt/gcsfuse_tokens/impactlab-data.json')\n",
    "store_filename = 'gs://impactlab-data/climate/source_data/GFDL-ESM4.ssp370.zarr'\n",
    "store = fs.get_mapper(store_filename, check=False)\n",
    "\n",
    "if not fs.exists(store_filename): \n",
    "    # save as a zarr store for rechunking \n",
    "    ds_model.to_zarr(store, consolidated=True, mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CMIP6 zarr store, this opens it as a dataset for inspection (note: MUST use path from above)\n",
    "ds_reloaded = xr.open_zarr(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      " ├── lat (180,) float64\n",
      " ├── lon (288,) float64\n",
      " ├── tasmax (31390, 180, 288) float32\n",
      " └── time (31390,) int64\n"
     ]
    }
   ],
   "source": [
    "# load CMIP6 zarr store as a zarr group, this is the version that rechunker needs \n",
    "source_group = zarr.open_consolidated(store, mode='r')\n",
    "print(source_group.tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_array = source_group['tasmax']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use `rechunker` package to rechunk CMIP6 model output from time chunks to space chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Rechunked</h2>\n",
       "        <details>\n",
       "          <summary><b>Source</b></summary>\n",
       "          <p><code>&lt;zarr.core.Array (31390, 180, 288) float32&gt;</code></p>\n",
       "        </details>\n",
       "        \n",
       "        <details>\n",
       "          <summary><b>Target</b></summary>\n",
       "          <p><code>&lt;zarr.core.Array (31390, 180, 288) float32&gt;</code></p>\n",
       "        </details>\n"
      ],
      "text/plain": [
       "<Rechunked>\n",
       "* Source      : <zarr.core.Array '/tasmax' (31390, 180, 288) float32 read-only>\n",
       "\n",
       "* Target      : <zarr.core.Array (31390, 180, 288) float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_chunks = {'time': 1, 'lat': 30, 'lon': 30}\n",
    "\n",
    "# unsure why, but specifying as a string was not working\n",
    "max_mem = 87091200\n",
    "\n",
    "tmp_storename = 'gs://impactlab-data/climate/source_data/GFDL-ESM4.ssp370_tmpchunks.zarr'\n",
    "target_storename = 'gs://impactlab-data/climate/source_data/GFDL-ESM4.ssp370_rechunk.zarr'\n",
    "\n",
    "temp_store = fs.get_mapper(tmp_storename, create=True)\n",
    "target_store = fs.get_mapper(target_storename, create=True)\n",
    "\n",
    "array_plan = rechunk(source_array, target_chunks, max_mem, target_store, temp_store=temp_store)\n",
    "array_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "with ProgressBar():\n",
    "    result = array_plan.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check target array to see if the output got rechunked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zarr.core.Array (31390, 180, 288) float32 read-only>\n"
     ]
    }
   ],
   "source": [
    "# open target array and double check that chunks are what we specified above\n",
    "source_array_rechunked = zarr.open(target_store, mode='r')\n",
    "print(source_array_rechunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30, 30)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check chunks\n",
    "source_array_rechunked.chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
